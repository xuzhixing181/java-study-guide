## 缓存介绍

- 缓存，即是数据交换的缓冲区（Cache），用于存储数据，一般读写性能较高
- 缓存的作用：
  - 降低后端负载
  - 提高读写效率，降低响应时间
- 缓存的成本：
  - 数据一致性成本
  - 代码维护和运维成本

## 缓存更新策略

- 内存淘汰：利用Redis的内存淘汰机制来更新缓存（惰性删除+定期删除），当内存不足时自动淘汰部分数据，下次查询时更新缓存
- 超时剔除：给缓存数据添加TTL时间，到期后自动删除缓存，下次查询时更新缓存
- 主动更新：编写业务逻辑，在修改数据库时更新缓存

根据业务场景来选择缓存更新策略：

- 低一致性需求：使用内存淘汰机制
- 高一致性需求：主动更新，并以超时剔除作为兜底方案

缓存主动更新策略分为Cache Aside Pattern（旁路缓存策略）、Read/Write Through Pattern（读写穿透）、Write Behind Pattern（异步缓存策略）

### Cache Aside Pattern

- Cache Aside Pattern（旁路缓存模式）：平时使用较多，适合读多写少的场景

  - 服务端需要同时维护数据库和缓存，且以数据库中的数据为准
  - 对于读操作：1）先更新数据库  2）在删除缓存
  - 对于写操作：1）先查询缓存  2）缓存未命中，则查询数据库并返回  3）重建缓存数据

- 举例说明：假设数据库和缓存中存在数据v都为10，线程1查询缓存未命中后查询数据库，查出的数据v = 10，

  其后，线程2更新数据库将v = 20，再删除缓存，线程1再写入缓存v = 10，

  而此时数据库中的数据v=20，缓存中的v=10，此时会出现数据不一致的情况，但概率极低，因为缓存的写入速度要远远快于数据库的写入速度，真实情况往往是单个线程先操作数据库，在操作缓存（如：线程2先更新数据库再删除缓存，线程1再查询缓存，未命中再查询数据库，写入缓存）

  =》为避免个别暂时数据不一致的情况，可在写入缓存时设定超时时间，缓存过期后，会走查询数据库更新缓存的逻辑

  ![image-20241230081457035](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241230081457035.png)

#### 先删除缓存，再更新数据库可以吗

- 举例说明：假设数据库和缓存中存在数据v都为10，线程1先删除缓存，与此同时，线程2查询缓存但未命中后，会查询数据库v=10，并写入缓存v=10，其后，线程1更新数据库v=20，其结果是缓存中v=10，数据库中v=20，由于缓存的写入速度要远远快于数据库的写入速度，所以这种情况发生的概率较大，出现数据不一致的风险较高

![image-20241230080405446](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241230080405446.png)

Cache Aside Pattern存在的问题：

- 问题1：首次请求数据一定不在缓存的问题
  - 解决方案：将热点数据提前存入缓存
- 问题2：写操作较频繁会导致缓存中的数据会被频繁删除，影响缓存命中率
  - 解决方案：
    - 针对强一致性场景，更新数据库的同时更新缓存，并通过锁/分布式锁来保证更新缓存时不存在线程安全问题
    - 针对允许短暂不一致的场景：更新数据库的同时更新缓存，并为缓存添加一个较短的过期时间，以保证即便出现数据不一致性，其影响也比较小

### Read/Write Through Pattern

- Read/Write Through Pattern模式下，缓存服务负责将数据读取和写入数据库，以减轻应用程序的职责
- 写操作（Write Through）：
  - 1）先查询缓存，缓存未命中再更新数据库
  - 2）缓存命中，则先更新缓存，由缓存服务自行更新数据库（客户端来看即是同时更新缓存和数据库）
- 读操作（Read Through）：
  - 1）从缓存中读取数据，读取到则就直接返回
  - 2）读取不到则从数据库加载，并写入到缓存后返回

- Read/Write Through Pattern实际只是在Cache Aside Pattern上进行了封装，在Cache Aside Pattern模式下，发送读请求时，如果缓存中不存在对应的数据，则由客户端负责将数据写入缓存，而Read/Write Through Pattern则由缓存自行写入缓存，该过程对客户端透明
- Read/Write Through Pattern和Cache Aside Pattern一样，首次请求数据不在缓存中，则可以将热点数据提前放入缓存

### Write Behind Pattern

- Write Behind Pattern 和 Read/Write Through Pattern 都是由**缓存服务来负责缓存和数据库的读写**

  其最大的不同在于Read/Write Through是同步更新缓存和数据库，而Write Behind 则是只直接更新缓存，**异步批量更新数据库**（而不是直接更新数据库），这对数据一致性带来较大挑战，如：缓存数据可能会没异步更新到数据库，缓存服务可能就挂了

- Write Behind Pattern（异步缓存写入）在平时开发中极为少见，但也不缺其应用场景，如：MQ中的消息异步写入磁盘、MySQL中的InnoDB Buffer Pool都用到了异步写入的策略

- Write Behind Pattern模式下，数据库的写性能非常高，非常适合一些数据频繁更新，且对数据一致性要求不高的场景，如：浏览量、点赞量

### 小结

缓存更新策略的最佳实践：

- 低一致性需求：使用Redis自带的内存淘汰机制
- 高一致性需求：主动更新，并以超时淘汰 作为兜底方案
  - 读操作：缓存命中则直接返回；**缓存未命中，则查询数据库，写入缓存并设定超时时间**
  - 写操作：**先写数据库，再删除缓存**；需确保数据库和缓存操作的原子性

## 缓存穿透

### 问题描述

- 缓存穿透：客户端请求的数据在缓存和数据库中都不存在，缓存永远不存在，请求打到数据库，会导致数据库的压力陡增，后续也无法构建缓存数据来缓解压力
- 导致缓存穿透的情况可能会有如下两种：
  - 1）业务误操作：缓存和数据库中的数据都被删除
  - 2）用户恶意攻击：故意大量访问某些不存在的业务数据

### 解决方案

#### 1）非法请求的限制

- 在API入口处新增对请求参数的校验（是否含有非法值、请求字段是否存在），如判断出是恶意请求就直接返回，避免进一步访问缓存和数据库
- 优缺点：实现简单，但对恶意请求的限制非常有限

#### 2）缓存空值或默认值

- 当线上业务发送缓存穿透时，可针对查询数据，在缓存中设置空值或默认值，后续请求就可从缓存中读取到空值或默认值后直接返回，而不会继续查询数据库

- 优缺点：实现简单，维护方便；但会额外地消耗内存，可能会造成短期的数据不一致

  ![image-20241229102807720](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241229102807720.png)

#### 3）布隆过滤器

- 使用布隆过滤器快速判断数据是否存在，如不存在则可直接返回，如存在才会放行请求，让其访问缓存等后续操作

- 优点：内存占用较少，没有多余key、

- 缺点：实现复杂，存在误判的概率，不能删除或更新数据

  ​           要根据业务场景**合理选择哈希函数的数量**和**布隆过滤器的大小**，以平衡准确性和空间效率

![image-20241229102721801](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241229102721801.png)



## 缓存击穿

### 问题描述

- 缓存击穿，也称为热点key问题，即被高并发访问且缓存重建业务较为复杂的key突然失效了，无数的请求访问会瞬间使数据库的压力陡增

  ![image-20241229114129213](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241229114129213.png)

- 缓存击穿常见的解决方案有互斥锁、逻辑过期

### 解决方案

#### 互斥锁

![image-20241229104801726](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241229104801726.png)

- 如上图所示，线程1如果查询缓存未命中，则获取互斥锁，获取到锁后**查询数据库**【重建缓存数据】，写入缓存后再释放锁；线程2查询缓存未命中，由于互斥锁已被线程1获取，线程2则无法再获取到互斥锁，只能休眠一段时间再重试，休眠期间，线程1可能完成了缓存数据的重建，线程2再次查询缓存，结果缓存命中，可直接返回

#### 逻辑过期

![image-20241229112419027](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241229112419027.png)

- 使用Hash结构，为数据新增表示 逻辑过期时间的时间戳字段，如上图，当线程1查询缓存，根据逻辑时间判断数据是否过期，如果已过期，则尝试获取互斥锁，获取成功则开启异步线程去重建缓存数据，当前线程则可立即返回过期数据 
  - 由异步线程去查询数据库并重建缓存数据，写入缓存重置逻辑过期时间，再释放锁
  - 其他线程再来查询缓存，如果发现逻辑时间已过期，且获取锁失败，会直接返回过期数据；如果逻辑时间没有过期，且缓存命中，则直接返回缓存数据

缓存击穿的解决方案总结：

| 解决方案 | 优点                  | 缺点                        |
| -------- | --------------------- | --------------------------- |
| 互斥锁   | 1）没有额外的内存消耗 | 1）线程需要等待，会影响性能 |
|          | 2）可保证数据一致性   | 2）有死锁风险               |
|          | 3）实现简单           |                             |
| 逻辑过期 | 线程无需等待，性能好  | 1）不保证数据的一致性       |
|          |                       | 2）有额外的内存消耗         |
|          |                       | 3）实现复杂                 |



## 缓存雪崩

- 缓存雪崩：在同一时段大量的缓存key同时失效或Redis服务宕机，导致大量请求到达数据库 使其压力陡增
- 解决方案：
  - 1）给不同key在TTL的基础上添加随机值，分散key的过期时间，避免大量缓存同时到期
  - 2）利用Redis集群提高服务可用性,避免单机出现问题导致整个缓存服务不可用(Redis Cluster 和 Redis Sentinel是最常用的集群实现方案)
  - 3）给缓存业务添加限流降级策略
  - 4）给业务添加多级缓存（如本地缓存+Redis远程缓存，当Redis缓存出现问题时，还可以从本地缓存中获取数据）
  - 5）缓存提前预热,即针对热点数据提前预热,将其存入缓存中并设置合理的过期时间(如秒杀场景下的数据在秒杀结束前不过期)

### 布隆过滤器

- 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？

  方案1：针对误判的情况，再加一层缓存，比如说某数据被误判为有，则查询数据库，记录为空，记到缓存里面，如果下次再访问该数据的时候，直接从缓存返回

  或者调整布隆过滤器参数或者用布谷鸟过滤器

  方案2：原始 key 通过 BloomFilter 检测一次，md5 后再通过另外一个 BloomFilter 检测一次

- 使用 Bloom Filter 只能添加新 key，不能删除某一个 key，如果想更好地更新维护，有什么其他方式吗？

  方案1：同上一个问题的方案1，维护一个删除的缓存

  方案2：参考Redis 的 Cuckoo Filter 的实现

  

## 缓存串讲：读多写少，如何解决数据更新缓存不同步？

### 缓存性价比

- 缓存很贵，不可滥用，需要考虑到使用缓存的性价比（数据量、查询频率、缓存命中率）
- 优化用户中心时，将用户账号信息存放到缓存，如下，该用户表有2000万条数据，主要用途是在用户登录时，通过用户提交的账号和秘密对数据库进行检索，确认用户账号和密码是否正确，查看账户是否被封禁，以此判定用户是否可登录

```sql
# 表结构
CREATE TABLE `accounts` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `account` varchar(15) NOT NULL DEFAULT '',
  `password` char(32) NOT NULL,
  `salt` char(16) NOT NULL,
  `status` tinyint(3) NOT NULL DEFAULT '0'
  `update_time` int(10) NOT NULL DEFAULT '0',
  `create_time` int(10) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

# 登录查询
select id, account, update_time from accounts 
where account = 'user1'
and password = '6b9260b1e02041a665d4e4a5117cfe16'
and status = 1
```

- 将2000万的用户数据存放缓存，绝对能提供很好的性能，但性价比不高，该表查询的场景主要用于账户登录，即使用户登录频繁，也不会造成太大的冲击（业务端有登录频次的限制），因此，缓存大部分时间是闲置状态
- 我们需要评估缓存是否有效，一般只有热点数据放到缓存才更有价值

### 临时热缓存

- 用户信息的使用频率很高，在很多场景下会被频繁查询，如：在论坛上看到发帖人头像、昵称、性别等，这些数据需要频繁展示，但这些数据总量很大，全部放入缓存很浪费空间

  =》优化：使用临时缓存，在用户信息被第一次使用时，同时将数据放到缓存中，短期内如果再次被查询就款速从缓存中获取，常见实现的代码如下：

  ```java
  import org.springframework.data.redis.core.RedisTemplate;
  import org.springframework.stereotype.Service;
  
  import javax.annotation.Resource;
  
  @Service
  public class UserInfoCacheService {
  
      @Resource
      private RedisTemplate<String, Object> redisTemplate;
  
      public Object getUserInfo() {
          // 尝试从缓存中直接获取用户信息
          Object userInfo = redisTemplate.opsForValue().get("user_info_9527");
          if (userInfo!= null) {
              // 缓存命中找到，直接返回用户信息
              return userInfo;
          }
  
          // 没有命中缓存，从数据库中获取
          Object userInfoFromDb = UserInfoModel.getUserInfoById(9527);
          if (userInfoFromDb!= null) {
              // 查找到用户信息，将用户信息缓存，并设置TTL超时时间让其60秒后失效
              redisTemplate.opsForValue().set("user_info_9527", userInfoFromDb, 60);
              return userInfoFromDb;
          }
  
          // 没有找到，放一个空数据进去，短期内不再问数据库
          // 可选，这个是用来预防缓存穿透查询攻击的
          redisTemplate.opsForValue().set("user_info_9527", "", 30);
          return null;
      }
  
      static class UserInfoModel {
          static Object getUserInfoById(int id) {
              // 模拟从数据库获取用户信息的逻辑
              // 这里返回实际从数据库查询的数据，暂时用null替代示例
              return null;
          }
      }
  }
  ```

- 代码如上，用户信息的数据只是临时存放到缓存，等待60秒过期后数据就会被淘汰，如果有同样的数据查询需要，数据需要重新写入缓存，这种**临时缓存适合表中数据量大、但热数据较少**的情况

  之所以**给缓存设置数据TTL，是为了节省内存空间**。当数据在一段时间内不被使用后就淘汰，不需要太大的内存，具有较高性价比，维护简单且常用

### 缓存更新不及时问题

- 临时缓存有TTL，如果60秒内修改了用户昵称，缓存可能不会马上更新（Cache Aside Pattern，即先操作数据库，再删除缓存，其后才重建缓存），最糟糕的情况是在60秒后才会刷新该用户昵称的缓存，出现缓存更新不及时的问题
- 对于缓存数据刷新，可分成几种情况，不同情况的刷新方式会有所不同

#### 单条实体数据刷新缓存

- 如下，缓存用户信息，当修改数据时，在数据更新时，同步更新对应的数据缓存

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

@Service
public class UserInfo {

    @Autowired
    private UserInfoDao userInfoDao;

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    // 更新用户昵称
    @Transactional
    public boolean updateUserNickname(int uid, String name) {
        // 先更新数据库
        boolean ret = userInfoDao.updateUserNickNameById(uid, name);
        if (ret) {
            // 然后清理缓存，让下次读取时刷新缓存，防止并发修改导致临时数据进入缓存
            // 这个方式刷新较快，使用很方便，维护成本低
            redisTemplate.delete("user_info_" + uid);
        }
        return ret;
    }
}

class UserInfoDao {
    // 模拟数据库更新操作
    public boolean updateUserNickNameById(int uid, String name) {
        // 这里应是真实的数据库更新逻辑，暂时用返回true模拟成功
        return true;
    }
}
```

- 先识别出被修改的数据ID，再根据ID删除被修改的数据缓存，等下次请求到来时，将最新的数据更新到缓存，有效减少并发操作将脏数据写入缓存的可能性

- 此外，还可以给队列发送更新消息让子系统更新，还可以开发中间件将对数据的操作发给子系统，自行决定更新的数据范围

  =》通过队列更新消息时存在的问题：条件批量更新的操作无法知道具体有多少个ID可能被修改

  - 常见方案：先同样的条件筛选出所有相关的ID，再更新数据库，用所有相关ID更新具体缓存即可

#### 关系型和统计型数据缓存刷新

##### 订阅数据库变更

- 订阅数据库，找到ID对应的数据变化，如下图，使用Canal，监控MySQL的数据更新，将变更信息推送Kafka内，我们可根据对应的表和具体的SQL确认更新操作 涉及的数据ID，再根据脚本内设定好的逻辑对相关key更新，如：9527的用户更新了昵称，则缓存更新服务就知道需要更新 `user_info_9527`的缓存，同时根据配置找到并删除其他 关联的缓存数据

  ![image-20250109073902811](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20250109073902811.png)

- 优点：能及时更新简单的缓存，同时核心系统会给子系统广播同步数据更改，实现简单；缺点：刷新复杂的关联关系，依旧需要通过人工写逻辑来实现

##### 版本号缓存设计

- 给表在数据库中的数据添加一个版本号，如：对`user_info`表设置一个版本号（`user_info_version`），该版本号记录在缓存中，当更新该表的数据时，直接对`user_info_version`加1；在数据写入缓存时，需要在缓存数据中记录`user_info_version`的当前值（缓存的键值对：key为user_info_uid，value为 用户数据+user_info_version）
- 当业务要读取`user_info`表中某个用户数据时，业务会同时获取当前表的版本，如果发现缓存数据内的版本和当前表的版本不一致，则更新该数据；但如果version更新很频繁，就会严重降低缓存命中率，该方案适合更新很少的表

**一旦有任何更新，整个表中所有数据缓存会一起过期**

![image-20250109080305539](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20250109080305539.png)



##### 数据范围拆分

- 对表做范围拆分，如按照ID范围分块拆分多个版本，来减少缓存刷新的范围和频率

### 长期热数据缓存

- 当TTL到期后，如果大量缓存没有命中，就会出现`缓存雪崩`，导致服务宕机
  - 所以，数据库要是扛不住平时的流量，就不能使用临时缓存的方式去设计系统，只能用长期缓存的方式来实现热点缓存
  - 要实现长期缓存，就需要人工做更多事情来保持缓存和数据库的数据一致性

#### 临时缓存和+长期热缓存

长期缓存要求业务几乎完全不走数据库，且服务运转期间所需的数据都能在缓存中找到，同时要保证使用期间缓存不会丢失

=》我们需要知道缓存中具体要有哪些数据，提前对这些数据预热；如果规模较小，则可考虑将全量数据都缓存起来

- 下面来实现一种`临时缓存+长期热缓存`的策略，该方式会有小规模缓存击穿，且代码相对负责，但总成本较低：

  ```java
  import org.springframework.data.redis.core.RedisTemplate;
  import org.springframework.data.redis.core.ValueOperations;
  import org.springframework.stereotype.Component;
  
  import javax.annotation.Resource;
  import java.util.concurrent.TimeUnit;
  
  @Component
  public class UserInfoCacheWithRedisTemplate {
  
      @Resource
      private RedisTemplate<String, Object> redisTemplate;
  
      public String getUserInfo() {
          ValueOperations<String, Object> valueOperations = redisTemplate.opsForValue();
          // 尝试从缓存中直接获取用户信息
          Object userinfo = valueOperations.get("user_info_9527");
          if (userinfo!= null) {
              // 缓存命中找到，直接返回用户信息
              return userinfo.toString();
          }
  
          // set 检测当前是否是热数据
          // 之所以没有使用Bloom Filter是因为有概率碰撞不准
          // 如果key数量超过千个，建议还是用Bloom Filter
          // 这个判断也可以放在业务逻辑代码中，用配置同步做
          Boolean isHotKey = redisTemplate.opsForSet().isMember("hot_key", "user_info_9527");
          if (isHotKey == null) {
              // "user_info_9527"对应的用户信息数据很可能是被频繁访问的热数据，将返回true；否则返回false
              // 如果 Redis 服务端出现异常，这个方法可能返回null
              return null;
          }
  
          // 如果是热key
          if (isHotKey) {
              // 没有找到就认为数据不存在
              // 可能是被删除了
              return "";
          }
  
          // 没有命中缓存，并且没被标注是热点，被认为是临时缓存，那么从数据库中获取
          // 设置更新锁set user_info_9527_lock nx ex 5
          // 防止多个线程同时并发查询数据库导致数据库压力过大
          Boolean lock = redisTemplate.opsForValue().setIfAbsent("user_info_9527_lock", "1", 5, TimeUnit.SECONDS);
          if (!lock) {
              // 没抢到锁的直接等待1秒 然后再拿一次结果，类似singleflight实现
              // 行业常见缓存服务，读并发能力很强，但写并发能力并不好
              // 过高的并行刷新会刷沉缓存
              try {
                  TimeUnit.SECONDS.sleep(1);
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
              // 等1秒后拿数据，这个数据是抢到锁的请求填入的
              // 通过这个方式降低数据库压力
              userinfo = valueOperations.get("user_info_9527");
              if (userinfo!= null) {
                  return userinfo.toString();
              }
              return null;
          }
  
          // 拿到锁的查数据库，然后填入缓存
          Object userinfoFromDb = UserInfoModelWithRedisTemplate.getUserInfoById(9527);
          if (userinfoFromDb!= null) {
              // 查找到用户信息
              // 将用户信息缓存，并设置TTL超时时间让其60秒后失效
              valueOperations.set("user_info_9527", userinfoFromDb, 60, TimeUnit.SECONDS);
              return userinfoFromDb.toString();
          }
  
          // 没有找到，放一个空数据进去，短期内不再问数据库
          valueOperations.set("user_info_9527", "", 30, TimeUnit.SECONDS);
          return null;
      }
  
      static class UserInfoModelWithRedisTemplate {
          static Object getUserInfoById(int id) {
              // 模拟从数据库获取用户信息的逻辑
              // 这里返回实际从数据库查询的数据，暂时用null替代示例
              return null;
          }
      }
  }
  ```

  

- 如上方式是长期缓存和临时缓存的混用，当要查询某个用户信息时，如果缓存中没有数据，长期缓存会直接返回数据不存在，临时缓存则直接走更新流程，此外，我们的用户信息如果属于热点key，且在缓存中找不到时，就直接返回数据不存在

  - 在更新期间，为防止高并发查询打垮数据库，可将更新流程进行简单的请求合并优化，**只有先抢到缓存更新锁的线程，才能进入后端读取数据库并将结果写入到缓存**；而**没有抢到更新锁的线程先睡眠1秒，再直接读取缓存返回结果**

    如此以保证后端不会有多个线程读取同一条数据，从而冲垮缓存和数据库服务

  - `hot_key`列表（长期缓存的热点key列表）会在多个Redis中复制保存，如果要读取`hot_key`，可随机选择一个分片就可获取到全量数据

- 这些热缓存key，来自于统计一段时间内的数据访问量 而 计算得出的热点数据，而**长期缓存的更新会通过异步脚本去定期扫描热缓存列表，来主动推送缓存**，同时将TTL设置成更长的时间来保证新的热数据缓存不会较快过期；当该热key不再被频繁访问后，热key会从当前set中移除，腾出空间来缓存其他数据
- 当然，如果我们拥有一个很大的缓存集群，且数据都属于热点数据，则大可以脱离数据库，将数据都放到缓存中直接对外提供服务，以便能获取到更好的吞吐量和并发



#### 业务服务器的小容量Redis

- 在每个业务服务器上部署一个小容量的Redis来保存热点缓存数据，通过脚本将热点数据同步到每个服务器的小Redis上，每次查询数据之前都会在本地小Redis查找，如果找不到再去大缓存中查找，通过该方式来缓解缓存的读取性能



### 小结

- 数据是否要放入缓存，我们要从数据量、使用频率、缓存命中率来分析

- 读多写少的数据做缓存在降低数据库压力的同时，也要根据一致性需求对缓存的数据做更新

  - 单条实体数据较容易实现缓存更新

  - 对于有条件查询的统计结果并不容易做到实时更新，其实现方案有：

    1）Canal监控数据库变更（binlog）并将变更消息推送到下游服务

    2）版本号缓存设计，给表增加版本号来标识，一旦表发生更新，表中所有数据都会过期

    3）根据ID对表进行范围拆分

- 除此之外，如果数据库承受不了请求压力，我们需要将一些热点数据改成长期缓存，来防止大量请求击穿缓存，以影响服务稳定

### 相关问题汇总

- Q1：缓存都是有超时时间的，从这个意义上说，都是“临时”的，为什么本文还要分为“临时”缓存和“长期”缓存？

  答：

  ```md
  大部分数据都有时效性，很少去做永久的内存缓存，需要考虑性价比。长期缓存可以是一天，临时缓存的TTL是30秒;
  
  长期缓存的更新是定期脚本刷新，临时缓存是用到才会放进去一会儿；
  
  长期的访问很频繁，如果放开会导致数据库压力很大，但是临时的由于访问量小所以不用特意防击穿。 
  ```

  

-  Q2：“临时”缓存和“长期”缓存在实现上可以用同一个软件吗？ 比如，两者都可以用Redis实现？或者，“临时缓存”是用一个组件实现（非Redis）而“长期缓存”用Redis实现？ 或者，“临时缓存”在代码中实现而“长期缓存”用Redis？

  答：

  ```md
  如果缓存压力不大可以用一个，如果很大会再做个L1缓存，在每台业务服务器上，这样能缓解核心缓存压力
  ```







