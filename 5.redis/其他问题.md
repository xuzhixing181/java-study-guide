## 如何同时更新所有节点上的本地缓存

在分布式系统中实现所有节点的本地缓存同步更新，可采用以下方案：

### 消息队列

- 实现方式：当某节点更新数据后，向消息队列发送缓存更新事件，所有节点都订阅该队列，接收到事件后更新本地缓存
- 优势：可靠，支持持久化和重试机制
- 注意事项：需处理消息顺序和幂等性（如通过唯一ID去重），消费者组模式下需要保证每个节点都独立消费

### 数据库日志监听

- 实现方式：使用Canal监听数据库的Binlog变化，解析变更事件后，通知所有节点更新缓存
- 优势：完全解耦应用层，可靠性高
- 注意事项：需额外引用中间件，增加架构复杂度

### HTTP广播

- 实现方式：节点更新数据后，向预定义的节点列表发送HTTP请求触发缓存刷新
- 优势：无中间件依赖
- 注意事项：节点动态扩容/缩容时维护列表困难，网络波动可能会导致部分请求失败，需要重试机制

### 发布订阅模式

- 实现方式：节点在数据更新后，通过Redis发布事件到指定频道；其他节点订阅该频道，触发本地缓存更新
- 优势：实时性强，实现简单
- 注意事项：无持久化，**节点离线期间的消息会丢失，需要结合数据库日志进行补偿**

#### 代码实现

- Redis配置类：

  ```java
  @Configuration
  @EnableCaching
  public class RedisConfig {
      @Value("${spring.redis.host}")
      private String host;
      @Value("${spring.redis.port}")
      private int port;
      @Value("${spring.redis.lettuce.pool.max-active:8}")
      private int maxActive;
  
      @Bean
      public LettuceConnectionFactory redisConnectionFactory() {
          LettucePoolConfig poolConfig = new LettucePoolConfig();
          poolConfig.setMaxTotal(maxActive);
          return new LettuceConnectionFactory(new RedisStandaloneConfiguration(host, port), poolConfig);
      }
  
      @Bean
      public RedisTemplate<String, Object> redisTemplate() {
          RedisTemplate<String, Object> template = new RedisTemplate<>();
          template.setConnectionFactory(redisConnectionFactory());
          template.setKeySerializer(RedisSerializer.string());
          template.setValueSerializer(RedisSerializer.json());
          template.setEnableTransactionSupport(true); // 启用事务
          return template;
      }
  
      @Bean
      public ChannelTopic cacheEvictTopic() {
          return new ChannelTopic("CACHE_EVICT_TOPIC");
      }
  }
  ```

- 定义消息体：

  ```java
  @Data
  @AllArgsConstructor
  @NoArgsConstructor
  public class CacheEvictMessage implements Serializable {
      private String messageId;       // 唯一消息ID
      private List<String> cacheNames; // 避免数组序列化问题
      private String key;             // 使用明确的键类型
      private Long timestamp;         // 用于过期清理
  }
  ```

- 缓存切面（支持SpEL解析）：

  ```java
  @Component
  public class CacheUpdateListener {
      private static final Logger logger = LoggerFactory.getLogger(CacheUpdateListener.class);
      private static final String PROCESSED_IDS_KEY = "cache:processed-messages";
      private static final String RETRY_QUEUE_KEY = "cache:evict:retry_queue";
      private static final String DEAD_LETTER_QUEUE_KEY = "cache:evict:dead_letter";
      private static final int MAX_RETRY_COUNT = 3;
      private static final long[] RETRY_DELAYS = {5_000, 30_000, 120_000}; // 重试延迟策略
  
      @Autowired
      private RedisTemplate<String, Object> redisTemplate;
      @Autowired
      private CacheManager cacheManager;
  
      // 内部重试消息包装类
      @Data
      @AllArgsConstructor
      @NoArgsConstructor
      private static class RetryMessage implements Serializable {
          private CacheEvictMessage originalMessage;
          private int retryCount;
      }
  
      @RedisListener(topics = "#{@cacheEvictTopic.topic}")
      public void handleMessage(CacheEvictMessage message) {
          // 幂等性检查
          Boolean isNew = redisTemplate.opsForValue().setIfAbsent(
                  PROCESSED_IDS_KEY + ":" + message.getMessageId(), 
                  "1", Duration.ofHours(24));
          if (Boolean.FALSE.equals(isNew)) {
              logger.debug("跳过重复消息: {}", message.getMessageId());
              return;
          }
  
          try {
              processCacheEvict(message);
          } catch (Exception ex) {
              logger.error("缓存清理失败, 进入重试流程: {}", message, ex);
              scheduleRetry(message, 0); // 首次重试
          }
      }
  
      private void processCacheEvict(CacheEvictMessage message) {
          message.getCacheNames().forEach(cacheName -> {
              Cache cache = cacheManager.getCache(cacheName);
              if (cache != null) {
                  if (StringUtils.hasText(message.getKey())) {
                      cache.evict(message.getKey());
                  } else {
                      cache.clear();
                  }
                  logger.info("清理缓存: {} - {}", cacheName, message.getKey());
              }
          });
      }
  
      // 重试逻辑核心
      private void scheduleRetry(CacheEvictMessage message, int retryCount) {
          if (retryCount >= MAX_RETRY_COUNT) {
              redisTemplate.opsForList().rightPush(DEAD_LETTER_QUEUE_KEY, message);
              // 更优方案(Redis Stream):
              // redisTemplate.opsForStream().add(DEAD_LETTER_QUEUE_KEY, message);
              logger.error("消息达到最大重试次数, 进入死信队列: {}", message);
              return;
          }
  
          long delayMs = RETRY_DELAYS[retryCount];
          RetryMessage retryMsg = new RetryMessage(message, retryCount + 1);
  
          // 使用Redis ZSET存储重试任务（score=当前时间+延迟时间）
          double executeTime = System.currentTimeMillis() + delayMs;
          redisTemplate.opsForZSet().add(RETRY_QUEUE_KEY, retryMsg, executeTime);
      }
  
      // 定时任务检查重试队列（每10秒执行一次）
      @Scheduled(fixedRate = 10_000)
      public void checkRetryQueue() {
          long now = System.currentTimeMillis();
          Set<RetryMessage> messages = redisTemplate.opsForZSet().rangeByScore(
                  RETRY_QUEUE_KEY, 0, now, 0, 100); // 每次处理100条
  
          messages.forEach(msg -> {
              // 原子操作：移除队列并处理
              if (redisTemplate.opsForZSet().remove(RETRY_QUEUE_KEY, msg) > 0) {
                  try {
                      processCacheEvict(msg.getOriginalMessage());
                  } catch (Exception ex) {
                      scheduleRetry(msg.getOriginalMessage(), msg.getRetryCount());
                  }
              }
          });
      }
  }
  ```

- 自定义注解**@BroadcastCacheEvict**：

  ```java
  @Target(ElementType.METHOD)
  @Retention(RetentionPolicy.RUNTIME)
  @CacheEvict
  public @interface BroadcastCacheEvict {
      String[] value();
      String key() default "";
      long ttl() default 3600; // 控制处理标记的过期时间（秒）
  }
  ```

- 业务端使用示例：

  ```java
  @Service
  public class DataService {
      
      @Resource
      private DataRepository dataRepository;
  
      @BroadcastCacheEvict(value = "dataCache", key = "#id")
      public Data updateData(Long id, Data newData) {
          Data updatedData = dataRepository.save(newData);
          return updatedData;
      }
  
      @Cacheable(value = "dataCache", key = "#id")
      public Data getData(Long id) {
          return dataRepository.findById(id).orElse(null);
      }
  }
  ```

#### 亮点总结

- **强一致性**：
  - 通过事务保证数据库更新与缓存通知的原子性
- **高可靠**：
  - Redis存储处理状态 + 消息重试机制
  - 本地缓存兜底防止雪崩

- **高性能**：
  - Lettuce连接池 + 非阻塞IO
  - 二级缓存减少Redis访问压力

- **易扩展**：
  - 可无缝切换为Kafka实现可靠队列
  - 支持动态调整缓存策略
