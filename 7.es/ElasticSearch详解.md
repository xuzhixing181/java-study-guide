# ElasticSearch基础

## ElasticSearch是什么

- ElasticSearch，即ES，基于Lucene实现的、高性能、高扩展性、高可用、支持持久化的**分布式实时全文搜索引擎**，可用于存储、快速检索和分析海量数据
- ES，对外提供Http接口，任何语言的客户端都可通过HTTP接口来接入ES，实现对数据的增删改查
- 全文检索，即指对每个词都建立一个索引，指明该关键词在文档中出现的次数和位置；当查询时，根据事先建立的索引进行查找，并查找的结果反馈给用户



## 基本概念

- index：类似于MySQL中的数据库，index（索引）用于存储数据，包含了一堆有相似结构的文档数据
- type：类似于MySQL中的数据表，type用于定义数据结构，type是index中的逻辑数据分类
- document：类似于MySQL中的行数据，但ES中的每个文档可以有不同的字段（json格式存储），对于通用字段有相同的数据类型
- field：类似于MySQL中的字段，一个document中可有多个field
- shard：即数据分片，单台机器无法存储大量数据，**ES可将一个index中的数据切分为多个shard**，**分布在多台机器上存储**；**基于shard可实现横向扩展**，存储更多数据，让**搜索和分析等操作分布在多台服务器上执行**，提升吞吐量和性能
- replica：
  - 服务副本，任何一个服务器随时可能出现故障或宕机，此时shard可能会丢失，可为每个shard创建多个replica副本
  - **replica可以在shard故障时提供提供备用服务**，以保证数据不丢失；多个replica可提升搜索操作的吞吐量和性能

## 倒排索引

- 在搜索引擎内，每个文档都有一个对应的文档ID，文档内容可看作为一系列关键词的集合

- 倒排索引，是关键词到文档ID的映射，每个关键词都出现在一系列的文本中

  举例来说，依次遍历文本是否含有"xlei"比较低效，高效的方法是对文本进行切分，如："xlei like coding"和"I like xlei"切分为"I"、"xlei"、"like"、"coding"多个部分，该操作称为分词，分词后的每部分是一个词项（Term），词项和文本id的映射就变成了类似于下面的样子：

  | Term   | 文本ID  |
  | ------ | ------- |
  | I      | 0，1，2 |
  | coding | 2，3，4 |
  | like   | 1，3    |
  | xlei   | 0，2    |
  | ...    | ...     |

- 将词项Term按照字典序从小到大排序，通过二分查找、时间复杂度O(logN) 的方式，可直接根据词项找到对应的文档ID

- 排好序的词项，称为 **Term Dictionary**，词项对应的文档ID、词频和词项在文本中的偏移量称为**Posting List**，Term Dictionary和Posting List共同构成了倒排索引（Inverted Index）

## Term Index

- 多个词项之间，可能会存在某些前缀是相同的，我们可以将Term Dictionary的部分词项提取出来，用这些**词项的前缀信息构建出一个精简的目录树**，用更少的空间来组织更多的词项

  =》**目录树的节点中存放这些词项在磁盘中偏移量**（指向磁盘中的位置），该目录树结构即为【**Term Index**】，体积小，适合放在内存中，用于加速搜索

![image-20241221150334581](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241221150334581.png)

- 当我们需要查找某词项时，只需要搜索Term Index，就能快速获得词项在Term Dictionary中的位置，再跳转到Term Dictionary，通过少量的检索，以定位到具体的词项内容



## Stored Fields

- **倒排索引，检索到的内容是文档ID**，我们需要通过该**文档ID**找到【完整的文档内容】，再返回给用户
  - **存放完整文档内容**的地方，即是**Stored Fields（行式存储）**

## Doc Values

- 用户经常需要根据某个字段来排序文档，比如，按照时间或商品价格排序，但这些字段分散在文档（document）中

  =》需要先获取Sorted Fields中的文档，再提取出内部字段进行排序，比较低效

  =》更高效的实现是，用空间换时间，再构造出一个**列式存储结构**，将**散落在各个文档中的某个字段集中存储**，当需要对某**字段排序**时，只需要**将这些集中存放的字段一次性读取出来**，如此就能针对性地进行排序，该列式存储结果，即是【**Doc Values**】

  ![image-20241221153532768](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241221153532768.png)





## Segment

- 如上所述，倒排索引（组织词项和文档ID等信息的映射）用于搜索，Term Index用于加速搜索（通过字典序排列，便于二分查找），Sorted Fields用于存放**文档完整的原始信息**，以及Doc Values用于**针对指定字段 进行排序和聚合**，这些结构共同组成【Segment】，Segment是一个**具备完整搜索功能的最小单元**

![image-20241221160505662](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241221160505662.png)

# ElasticSearch架构解析

- 从架构角度来看，ES让**单机系统**Lucene**变为一个分布式系统**提供了一套解决方案

## Lucene

- 一个Segment可包含多个文档，如果新增文档（可理解为行数据）时，还是写入到这份Segment，就需要同时更新Segment内部的多个数据结构，会影响到并发读写性能，为避免影响，需要保证**Segment一旦生成，就不能再被修改**；如果要写入新的文档，则需要生成新的Segment=》**老Segment只负责读，写操作则生成新的Segment**，以保证数据读写的性能
- Segment变多了，可通过**并发同时读多个Segment**来提高吞吐量和性能

- 随着数据量的增大，Segment文件越写越多，文件句柄总会被耗尽
  - 解决方案：不定期合并多个小Segment为大Segment，即**段合并**（Segment Merging），以保证文件数量可控
- **多个Segment共同构成一个单机文本检索库**（开源搜索库Lucene），ES即是基于Lucene来构建的
- Lucene比较简单，并不能保证高性能、高扩展性、高可用，ES对其优化如下所述

## 高性能

- Lucene可写入大量数据，并对外提供检索能力；多个调用方同时读写同一个Lucene会导致计算资源被争抢，抢不到资源的调用方就会等待

  解决方案：

  - 对写入Lucene的数据进行分类（如分为商品数据和订单数据等），每个类都是一个Index Name，根据Index Name新增Lucene的数量

  - 将不同分类的数据写入到不同的Lucene；读取数据时，根据需要，读取不同的Index Name对应的Lucene，大大降低单个Lucene的压力

- 单个Index Name内的数据可能过多，可**将单个Index Name的同类数据拆分成多份**（多个shard分片），**每个shard分片本质上即是一个独立的Lucene库**，如此，将读写操作分摊到多个分片中，以降低对资源的争抢，提升系统性能

  ![image-20241221165117196](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241221165117196.png)

  

  

## 高扩展性

- 随着分片变多，如果分片都在同一台机器上，就会导致单机CPU和内存过载，影响系统整体性能

  =》解决方案：扩展更多机器，将shard分片 分散部署在多台机器上，每台机器就是一个Node，可通过**增加Node来缓解机器CPU过载带来的性能问题**

## 高可用

- 如果集群中的某个Node挂了，则Node中的所有分片都无法对外提供服务

  - 解决方案：给分片多增加副本
  - 分片分为`Primary shard`和`Replica shard`，即主分片和副本分片，主分片会将数据同步给副本分片，副本分片可提供读操作，还能在主分片挂了后，升级为新的主分片，以保证让系统正常运行，提高系统性能的同时，还保证了系统的高可用

  ![image-20241221172100968](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241221172100968.png)



## Node角色分化

- 搜索架构需要支持的功能很多，既要负责管理集群，又要存储管理数据，还要处理客户端的搜索请求，如果每个Node都支持这些功能，则当集群有压力需要扩容Node时，就会顺带将其他能力也一起扩容，但可能其他能力完全够用，扩容相应能力会浪费资源
  - 优化方案：拆分这些功能，**给集群中的Node赋予不同的角色，不同的角色负责不同的功能**，角色如下：
    - 主节点（Master Node）：负责管理集群
    - **数据节点**（Data Node）：负责**存储、管理数据**
    - **协调节点**（Coordinate Node）：负责**接收客户端的搜索和查询请求**
  - 当集群规模较小时，一个Node可同时充当多个角色；规模较大时，可让一个Node充当一个角色



## 去中心化

- 每个Node都是独立的，因此需要通过某种机制来协调Node之间的数据

  解决方案：

  - 1）像Kafka引入中心节点Zookeeper

  - 2）在**Node之间引入协调模块**，用**一致性算法Raft，**在**节点间相互同步数据**，**让所有Node看到的集群数据状态都是一致的**

    如此，集群内的**Node能参与选主过程**，还能得知集群内某个Node是否健康等信息



# ES操作数据流程

## 写数据流程

- 1）当客户端应用发起数据写入请求，请求会先发送到集群中的协调节点

- 2）协调节点**根据hash路由**，判断数据该写入到哪个**数据节点**中的哪个**主分片**（Shard），找到主分片并写入

  分片底层是Lucene（即最终将数据写入到Lucene库中的segment中），将数据结构化为倒排索引、Stored Fields和Doc Values等多种数据结构

- 3）主分片写入成功后，会将数据同步给副本分片

- 4）副本分片写入完成后，主分片会响应协调节点ACK，表示数据写入完成

- 5）协调节点响应客户端应用 数据写入完成

![image-20241222104450310](C:\Users\xyl\AppData\Roaming\Typora\typora-user-images\image-20241222104450310.png)

![image](https://github.com/user-attachments/assets/c7722363-946c-4f3d-ba7b-a7d9567551e1)




## 更新和删除流程

- 更新和删除数据，本质上都是写操作，但ES中的document不可变，因此document不能被删除或改动来表示其变更操作

  =》通过.del文件来标识文档是否被删除，磁盘上的每个Segment都有一个对应的 .del文件

- 如果是删除操作，document在 .del文件中会被标识为deleted状态，该文档依旧会匹配查询，但会在结果中进行过滤

- 如果是更新操作，旧document会被标识为deleted状态，其后会再创建一个新的document



##  搜索数据流程

- ES的搜索流程分为**查询阶段**（Query Phase）和**获取阶段**（Fetch Phase）

### 查询阶段

- 1）当客户端应用发起**搜索请求**，请求会**先发送到集群中的协调节点**
- 2）协调节点根据Index Name的信息，**得知Index Name拆分后的分片数量**，以及这些**分片分散在哪个数据节点上**，并将**请求转发到这些数据节点的分片上**
- 3）搜索请求到达分片后，分片底层的Lucene库会**并发搜索到多个Segment**（多个Segment组织成Lucene库），利用每个**Segment内部的倒排索引获取对应的文档ID**，并结合**Doc Values**（根据指定字段排序的文档）获取倒排信息，分片将**结果聚合返回给协调节点**
- 4）协调节点**对多个分片中获取到的数据**进行**排序聚合**，**舍弃大部分不需要的数据**

### 获取阶段

- 5）协调节点再次根据文档ID 请求数据节点中的分片，分片底层的Lucene库会从Segment内部的Stored Fields中取出完整的文档内容，并返回给协调节点
- 6）协调节点将数据结果返回给客户端，完成整个搜索过程

# 总结

- **Lucene**是ES底层的单机文本检索库，**由多个Segment组成**，每个Segment是由**倒排索引、Term Index、Stored Fiels、**

  **Doc Values**组成的、具备**完整搜索功能**的最小单元

- 为提供数据写入和检索的功能，将数据分类，每个类都是一个Index Name，会根据Index Name新增Lucene的数量

- 为防止Index Name内数据过多，引入Shard对数据分片，以提升性能

- 多个Shard会被分散到多个Node上，可根据需要对Node扩容，提升扩展性

  - Shard分为主分片和副本分片，如果主分片挂了，副本分片会切换为主分片，如此以保障系统的可用性
  - 对Node进行角色分化，提高系统的性能和资源利用率，同时简化扩展和维护



























































